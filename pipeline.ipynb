{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "import jsonlines\n",
    "import json\n",
    "import os\n",
    "\n",
    "with open('metafiles/mlda_data.json', 'r') as f:\n",
    "    metas = json.loads(f.read())\n",
    "\n",
    "list_of_keys = [k for k in metas.keys()]\n",
    "for idx, key in enumerate(list_of_keys[:10]):\n",
    "    url = metas[key][\"url\"]\n",
    "    YouTube(url).streams.first().download(filename=\"download_videos/\"+key+\".mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cut Videos using cut_videos_mlda.py (given python code)<br>\n",
    "* Move the videos into a folder: data/original<br>\n",
    "* The following code will split each clip into frames and save it in: data/image split\n",
    "\n",
    "### Frames Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "root_dir = 'data/original/'\n",
    "\n",
    "for subdir, dirs, files in os.walk(root_dir):\n",
    "    save_folder = 'data/image split/' + (str(subdir).split(\"/\")[-1])\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "\n",
    "    for file in tqdm(files):\n",
    "        filepath = str(subdir) + '/' + file\n",
    "        vid = cv2.VideoCapture(filepath)\n",
    "        total_frames = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "        \n",
    "        try:\n",
    "            temp = int(total_frames/fps)\n",
    "        except ZeroDivisionError:\n",
    "            temp = 0\n",
    "        \n",
    "        frames_to_extract = temp if temp < 11 else 10\n",
    "        uniform_frame_array = np.linspace(0, frames_to_extract, num=frames_to_extract+1, dtype=int).tolist()\n",
    "        \n",
    "        frame_counter = 0\n",
    "        while True:\n",
    "            ret, frame = vid.read()\n",
    "            if ret == False:\n",
    "                break\n",
    "            if frame_counter in uniform_frame_array:\n",
    "                save_path = f'{save_folder}/{file}_{frame_counter}.png'\n",
    "                cv2.imwrite(save_path, frame)\n",
    "\n",
    "            frame_counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Captioning for each Frame using GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from glob2 import glob\n",
    "from transformers import pipeline\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "caption_dict = {}\n",
    "\n",
    "root_dir = 'data/image split'\n",
    "for subdir, dirs, files in os.walk(root_dir):\n",
    "   for dir in dirs:\n",
    "    imgs_path = root_dir + '/' + dir + '/*'\n",
    "    imgs = glob(imgs_path)\n",
    "    image_to_text = pipeline(\"image-to-text\", model=\"nlpconnect/vit-gpt2-image-captioning\", device=0)\n",
    "      \n",
    "    for img in tqdm(imgs):\n",
    "        caption = image_to_text(img)[0]['generated_text']\n",
    "        clip_id = img.rsplit(\"_\",1)[0]\n",
    "        if clip_id in caption_dict:\n",
    "            caption_dict[clip_id].append(caption)\n",
    "        else:\n",
    "            caption_dict[clip_id] = [caption]\n",
    "    print(caption_dict)\n",
    "\n",
    "with open(\"VIT_GPT2_captions.json\", \"w\") as outfile:\n",
    "    json.dump(caption_dict, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Similarity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "class SimilarityScores:\n",
    "  \n",
    "    def __init__(self, captions_list) -> None:\n",
    "        self.captions = captions_list\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.processed_captions = [self.preprocess_caption(caption) for caption in self.captions]\n",
    "        self.jaccard_matrix = [[self.jaccard_similarity(c1, c2) for c2 in self.processed_captions] for c1 in self.processed_captions]\n",
    "\n",
    "    def preprocess_caption(self, caption):\n",
    "        lowercase = caption.lower()\n",
    "        tokens = word_tokenize(lowercase)\n",
    "        filtered_tokens = [word for word in tokens if word not in self.stop_words]\n",
    "        return filtered_tokens\n",
    "\n",
    "    def jaccard_similarity(self, caption1, caption2):\n",
    "        intersection = len(set(caption1) & set(caption2))\n",
    "        union = len(set(caption1) | set(caption2))\n",
    "        return intersection / union if union else 0\n",
    "\n",
    "    def find_most_similar(self, matrix):\n",
    "        average_similarities = [sum(row) / len(row) for row in matrix]\n",
    "        return self.captions[average_similarities.index(max(average_similarities))]\n",
    "    \n",
    "    def get_Jaccard_similarity_scores_between_2_captions(self):\n",
    "        val = self.jaccard_matrix[0][1]\n",
    "        return val\n",
    "\n",
    "    def get_highest_eval_by_Jaccard(self):\n",
    "       most_similar_jaccard = self.find_most_similar(self.jaccard_matrix)\n",
    "       return most_similar_jaccard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Caption for each video and METEOR Scores comparing original caption and best caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from scores import SimilarityScores\n",
    "from nltk.translate import meteor\n",
    "from nltk import word_tokenize\n",
    "\n",
    "captions_dict = {}\n",
    "original_captions = {}\n",
    "final_json = {}\n",
    "with open('VIT_GPT2_captions.json') as json_data:\n",
    "    temp = json.load(json_data)\n",
    "    captions_dict = {key.split(\"\\\\\")[-1].rsplit(\".\",1)[0]: temp[key] for key in temp.keys()}\n",
    "\n",
    "with open('mlda_data_abridged.json') as json_data:\n",
    "    temp = json.load(json_data)   \n",
    "    final_json = temp \n",
    "    for key, video in temp.items():\n",
    "        clips = video['clip']\n",
    "        for name, val in clips.items():\n",
    "            for scene in val['scene_split']:\n",
    "                original_captions[scene['clip_id']] = scene['caption']    \n",
    "\n",
    "for key, captions_list in captions_dict.items():\n",
    "    best_caption_generator = SimilarityScores(captions_list=captions_list)\n",
    "    best_caption = best_caption_generator.get_highest_eval_by_Jaccard()\n",
    "\n",
    "    original_caption = original_captions[key]\n",
    "    score = round(meteor([word_tokenize(best_caption)], word_tokenize(original_caption)),4)\n",
    "    video_name = str(key.rsplit(\"_\",1)[0]) + \".mp4\"\n",
    "    main_scene_split = final_json[key.rsplit(\".\",1)[0]]['clip'][video_name]['scene_split']\n",
    "    for scene in main_scene_split:\n",
    "        if scene['clip_id'] == key:\n",
    "            if score < 0.15:\n",
    "                main_scene_split.remove(scene)\n",
    "            else:\n",
    "                scene['score'] = score\n",
    "    final_json[key.rsplit(\".\",1)[0]]['clip'][video_name]['scene_split'] = main_scene_split\n",
    "\n",
    "with open(\"final_mlda_data.json\", \"w\") as outfile:\n",
    "    json.dump(final_json, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
